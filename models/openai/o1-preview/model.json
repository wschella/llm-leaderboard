{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "o1-preview",
  "description": "A research preview model focused on mathematical and logical reasoning capabilities, demonstrating improved performance on tasks requiring step-by-step reasoning, mathematical problem-solving, and code generation. The model shows enhanced capabilities in formal reasoning while maintaining strong general capabilities.",
  "release_date": "2024-09-12",
  "input_context_size": 128000,
  "output_context_size": 32768,
  "license": "Proprietary",
  "multimodal": false,
  "web_hydrated": false,
  "knowledge_cutoff": "2023-12",
  "api_ref_link": "https://platform.openai.com/docs/models",
  "playground_link": null,
  "paper_link": "https://cdn.openai.com/o1-system-card-20240917.pdf",
  "scorecard_blog_link": "https://openai.com/index/learning-to-reason-with-llms",
  "repo_link": "https://github.com/openai",
  "weights_link": null,
  "param_count": null,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "MATH",
      "score": 0.855,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms"
    },
    {
      "dataset_name": "MMLU",
      "score": 0.908,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.733,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "AIME 2024",
      "score": 0.42,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MGSM",
      "score": 0.908,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "SWE-bench Verified",
      "score": 0.413,
      "is_self_reported": true,
      "analysis_method": "Verified",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "LiveBench",
      "score": 0.523,
      "is_self_reported": true,
      "analysis_method": "Coding",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "SimpleQA",
      "score": 0.424,
      "is_self_reported": true,
      "analysis_method": "Factuality",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    }
  ]
}
